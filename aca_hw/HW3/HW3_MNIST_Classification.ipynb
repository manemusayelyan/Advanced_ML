{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Jc_lbGgJ2kl"
      },
      "source": [
        "# **MNIST Classification**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxuC6LfRKI5H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI6KifjJKymh"
      },
      "outputs": [],
      "source": [
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "\n",
        "X = X / 255.0\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "non_zero_mask = (X != 0).any(axis=0)\n",
        "X = X.loc[:, non_zero_mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ph0AdPJhLu1H"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "pca = PCA(n_components=100, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QQGZ-aoMvBf"
      },
      "source": [
        "# **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52s4sHVhMEhA"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, alpha=0.01, eps=1e-4, max_iter=2000):\n",
        "        self.alpha = alpha\n",
        "        self.eps = eps\n",
        "        self.max_iter = max_iter\n",
        "        self.weights = None\n",
        "        self.classes = None\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def _add_bias(self, X):\n",
        "        return np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "    def logistic_regression(self, X, y):\n",
        "        m, n = X.shape\n",
        "        w = np.zeros(n)\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            y_pred = self.sigmoid(X @ w)\n",
        "            gradient = (X.T @ (y_pred - y)) / m\n",
        "            if np.linalg.norm(gradient) < self.eps:\n",
        "                break\n",
        "            w -= self.alpha * gradient\n",
        "\n",
        "        return w\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = self._add_bias(X)\n",
        "        self.classes = np.unique(y)\n",
        "        self.weights = []\n",
        "\n",
        "        for c in self.classes:\n",
        "            y_c = (y == c).astype(int)\n",
        "            w_c = self.logistic_regression(X, y_c)\n",
        "            self.weights.append(w_c)\n",
        "\n",
        "        self.weights = np.array(self.weights)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = self._add_bias(X)\n",
        "        probs = self.sigmoid(X @ self.weights.T)\n",
        "        return self.classes[np.argmax(probs, axis=1)]\n",
        "\n",
        "model_logistic = LogisticRegression(alpha=0.01, max_iter=2000)\n",
        "model_logistic.fit(X_train_pca, y_train)\n",
        "y_pred_lr = model_logistic.predict(X_test_pca)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2fIs_l9Ne0M",
        "outputId": "b61c2ed0-6b82-4168-f53d-19525e23d895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of Logistic Regression with PCA: 0.8729\n",
            "F1 Score of Logistic Regression with PCA: 0.8716\n",
            "Precision Score of Logistic Regression with PCA: 0.8734\n",
            "Recall Score of Logistic Regression with PCA: 0.8729\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy of Logistic Regression with PCA: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
        "print(f\"F1 Score of Logistic Regression with PCA: {f1_score(y_test, y_pred_lr, average='weighted'):.4f}\")\n",
        "print(f\"Precision Score of Logistic Regression with PCA: {precision_score(y_test, y_pred_lr, average='weighted'):.4f}\")\n",
        "print(f\"Recall Score of Logistic Regression with PCA: {recall_score(y_test, y_pred_lr, average='weighted'):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql4wG7nkNmiu"
      },
      "source": [
        "# **Quadratic Discriminant Analysis (QDA)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyyDEIQtI8uL"
      },
      "outputs": [],
      "source": [
        "class QDA:\n",
        "    def __init__(self):\n",
        "        self.labels = None\n",
        "        self.means = {}\n",
        "        self.covariance_matrices = {}\n",
        "        self.covariance_matrix_inverses = {}\n",
        "        self.label_log_probabilities = {}\n",
        "    @staticmethod\n",
        "    def get_stats(x):\n",
        "        mean = np.mean(x, axis=0)\n",
        "        covariance_matrix = np.cov(x.T, ddof=1)\n",
        "        return mean, covariance_matrix\n",
        "    @staticmethod\n",
        "    def get_label_log_probabilities(y):\n",
        "        return np.log(np.bincount(y)/len(y))\n",
        "\n",
        "    def qdf(self, x, mean, covariance_matrix_inverse):\n",
        "        cov_mean = covariance_matrix_inverse @ mean\n",
        "        return (-1/2*np.log(np.linalg.det(covariance_matrix_inverse))\n",
        "                -1/2 * (mean.T @ cov_mean) + x @ cov_mean - 1/2 * np.diag(x @ covariance_matrix_inverse @ x.T))\n",
        "\n",
        "    def fit(self, x_train, y_train):\n",
        "        self.labels = np.unique(y_train)\n",
        "        label_log_probabilities = self.get_label_log_probabilities(y_train)\n",
        "        self.label_log_probabilities = dict(zip(self.labels, label_log_probabilities))\n",
        "        for label in self.labels:\n",
        "            x_labeled = x_train[y_train == label]\n",
        "            mean, covariance_matrix = self.get_stats(x_labeled)\n",
        "            self.means[label] = mean\n",
        "            self.covariance_matrices[label] = covariance_matrix\n",
        "            covariance_matrix_inverse = np.linalg.inv(covariance_matrix)\n",
        "            self.covariance_matrix_inverses[label] = covariance_matrix_inverse\n",
        "\n",
        "    def predict(self, x_test):\n",
        "        log_posteriors = self.predict_probabilities(x_test)\n",
        "        return self.labels[np.argmax(log_posteriors, axis=0)]\n",
        "\n",
        "    def predict_probabilities(self, x_test):\n",
        "        probabilities = []\n",
        "        for label in self.labels:\n",
        "            mean = self.means[label]\n",
        "            covariance_matrix_inverse = np.linalg.inv(self.covariance_matrices[label])\n",
        "            prob = self.qdf(x_test, mean, covariance_matrix_inverse) + self.label_log_probabilities[label]\n",
        "            probabilities.append(prob)\n",
        "        return np.array(probabilities)\n",
        "\n",
        "model_qda = QDA()\n",
        "model_qda.fit(X_train_pca, y_train)\n",
        "y_pred_qda = model_qda.predict(X_test_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXU_wBm4HCEa",
        "outputId": "de6fbb43-3cf0-423a-edb5-c1a3e15abc04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of QDA: 0.7372\n",
            "F1 Score of QDA: 0.7070\n",
            "Precision Score of QDA: 0.7158\n",
            "Recall Score of QDA: 0.7372\n"
          ]
        }
      ],
      "source": [
        "# change PCA components to 30\n",
        "print(f\"Accuracy of QDA: {accuracy_score(y_test, y_pred_qda):.4f}\")\n",
        "print(f\"F1 Score of QDA: {f1_score(y_test, y_pred_qda, average='weighted'):.4f}\")\n",
        "print(f\"Precision Score of QDA: {precision_score(y_test, y_pred_qda, average='weighted', zero_division=0):.4f}\")\n",
        "print(f\"Recall Score of QDA: {recall_score(y_test, y_pred_qda, average='weighted'):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNnWTBGSMEBS"
      },
      "source": [
        "# **Support Vector Machine (SVM)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3SUJZki_MDT-"
      },
      "outputs": [],
      "source": [
        "class SVM:\n",
        "    def __init__(self, C=1.0, alpha=0.01, iter=100):\n",
        "        self.C = C\n",
        "        self.alpha = alpha\n",
        "        self.iter = iter\n",
        "        self.models = {}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes = np.unique(y)\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        for label in self.classes:\n",
        "            w = np.zeros(n_features)\n",
        "            b = 0\n",
        "            y_binary = np.where(y == label, 1, -1)\n",
        "\n",
        "            for _ in range(self.iter):\n",
        "                for i in range(n_samples):\n",
        "                    cond = y_binary[i] * (X[i] @ w + b) >= 1\n",
        "                    if cond:\n",
        "                        dw = w\n",
        "                        db = 0\n",
        "                    else:\n",
        "                        dw = w - self.C * y_binary[i] * X[i]\n",
        "                        db = -self.C * y_binary[i]\n",
        "                    w -= self.alpha * dw\n",
        "                    b -= self.alpha * db\n",
        "\n",
        "            self.models[label] = (w, b)\n",
        "\n",
        "    def predict(self, X):\n",
        "        n_samples = X.shape[0]\n",
        "        scores = np.zeros((n_samples, len(self.models)))\n",
        "\n",
        "        for i, label in enumerate(self.models):\n",
        "            w, b = self.models[label]\n",
        "            scores[:, i] = X @ w + b\n",
        "\n",
        "        predictions = np.argmax(scores, axis=1)\n",
        "        return self.classes[predictions]\n",
        "\n",
        "\n",
        "model_svm = SVM(C=1.0, alpha=0.01, iter=100)\n",
        "model_svm.fit(X_train_pca, y_train)\n",
        "y_pred_svm = model_svm.predict(X_test_pca)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmJZ21-ML773"
      },
      "source": [
        "# **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMk1nSU-fGsD"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "class RandomForest:\n",
        "    def __init__(self, n_estimators=100, max_depth=None, n_features=None, random_state=None):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.n_features = n_features\n",
        "        self.random_state = random_state\n",
        "        self.trees = []\n",
        "    def bootstrap_sample(self, X, y):\n",
        "        n_samples = X.shape[0]\n",
        "        idx = np.random.choice(n_samples, size=n_samples, replace=True)\n",
        "        return np.array(X)[idx], np.array(y)[idx]\n",
        "    def get_rand_features(self, X):\n",
        "        n_features = X.shape[1]\n",
        "        if self.n_features is None:\n",
        "            self.n_features = int(np.sqrt(n_features))\n",
        "        features_idx = np.random.choice(n_features, self.n_features, replace=False)\n",
        "        return features_idx\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        np.random.seed(self.random_state)\n",
        "        for _ in range(self.n_estimators):\n",
        "            X_sample, y_sample = self.bootstrap_sample(X, y)\n",
        "            features_idx = self.get_rand_features(X_sample)\n",
        "            X_sample_rand_features = X_sample[:, features_idx]\n",
        "            tree = DecisionTreeClassifier(max_depth=self.max_depth, random_state=self.random_state)\n",
        "            tree.fit(X_sample_rand_features, y_sample.astype(int))\n",
        "            self.trees.append((tree, features_idx))\n",
        "\n",
        "    def predict(self, X):\n",
        "        tree_preds = []\n",
        "        for tree, features_idx in self.trees:\n",
        "            X_selected = X[:, features_idx]\n",
        "            pred = tree.predict(X_selected)\n",
        "            tree_preds.append(pred)\n",
        "\n",
        "        tree_preds = np.array(tree_preds)\n",
        "        final_preds = []\n",
        "\n",
        "        for i in range(tree_preds.shape[1]):\n",
        "            votes = tree_preds[:, i]\n",
        "            majority_vote = np.bincount(votes.astype(int)).argmax()\n",
        "            final_preds.append(majority_vote)\n",
        "\n",
        "        return np.array(final_preds)\n",
        "\n",
        "model_rf = RandomForest(n_estimators=100, max_depth=20, random_state=42)\n",
        "model_rf.fit(X_train_pca, y_train)\n",
        "y_pred_rf = model_rf.predict(X_test_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WESGtsyXhWod",
        "outputId": "0c60d1ed-f8e9-49ca-9dca-61323be7eada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of Random Forest: 0.9136\n",
            "F1 Score of Random Forest: 0.9135\n",
            "Precision Score of Random Forest: 0.9141\n",
            "Recall Score of Random Forest: 0.9136\n"
          ]
        }
      ],
      "source": [
        "y_test = y_test.astype(int)\n",
        "y_pred_rf = y_pred_rf.astype(int)\n",
        "\n",
        "# change PCA components to 100-150\n",
        "print(f\"Accuracy of Random Forest: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"F1 Score of Random Forest: {f1_score(y_test, y_pred_rf, average='weighted'):.4f}\")\n",
        "print(f\"Precision Score of Random Forest: {precision_score(y_test, y_pred_rf, average='weighted'):.4f}\")\n",
        "print(f\"Recall Score of Random Forest: {recall_score(y_test, y_pred_rf, average='weighted'):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8__-r2tVi2FT"
      },
      "source": [
        "# **Report about MNIST dataset and Implementations**\n",
        "\n",
        "The MNIST dataset is a large collection of handwritten digits commonly used for evaluating machine learning algorithms in the field of computer vision and image processing.The dataset consists of 70,000 datapoints each representing a digit from 0 to 9. Each image is 28x28 pixels and represents one of the 10 possible classes (digits 0 to 9).\n",
        "The pixel values of the images are normalized to the range [0, 1] by dividing by 255.The dataset is split into training and testing sets using train_test_split, with 80% of the data used for training and 20% for testing.\n",
        " A mask is created to select features that have non-zero values across all images, effectively removing features that are all zeros (columns that contain only background pixels).The data is scaled using StandardScaler to standardize the features by removing the mean and scaling to unit variance.\n",
        " PCA is applied to reduce the dimensionality of the data.It helps in retaining the most significant features and reducing the computational cost of subsequent machine learning models.\n",
        "\n",
        " **Logistic Regression** struggled with the high dimensionality of the original MNIST dataset (784 features). To address this, Principal Component Analysis (PCA) was applied to reduce the feature space to 150 components, improving both performance and training efficiency.\n",
        "\n",
        " **Quadratic Discriminant Analysis (QDA)** was more sensitive to high dimensionality, so the number of PCA components was further reduced to 30 to avoid issues like singular covariance matrices and to improve model stability.\n",
        "\n",
        " For the **SVM** implementation, an attempt was made to use the cvxopt solver, but due to RAM limitations, it was not feasible. Instead, a custom SVM was implemented using Stochastic Gradient Descent (SGD), with 100 PCA components and 100 training iterations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "OdXLxBWIi1z0",
        "outputId": "13b3ff67-e6a0-471f-80d8-7e99bd233faa"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Mix of label input types (string and number)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-82f098f72ec3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     ],\n\u001b[1;32m      9\u001b[0m     'F1 Score': [\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_qda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_svm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.66666667\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m        \u001b[0;34m,\u001b[0m \u001b[0;36m0.66666667\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \"\"\"\n\u001b[0;32m-> 1324\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1325\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1515\u001b[0m     \"\"\"\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1517\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1518\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1828\u001b[0m     \"\"\"\n\u001b[1;32m   1829\u001b[0m     \u001b[0m_check_zero_division\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1830\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
          ]
        }
      ],
      "source": [
        "metrics = {\n",
        "    'Model': ['Logistic Regression (PCA)', 'QDA', 'SVM', 'Random Forest'],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred_lr),\n",
        "        accuracy_score(y_test, y_pred_qda),\n",
        "        accuracy_score(y_test, y_pred_svm),\n",
        "        accuracy_score(y_test, y_pred_rf)\n",
        "    ],\n",
        "    'F1 Score': [\n",
        "        f1_score(y_test, y_pred_lr, average='weighted'),\n",
        "        f1_score(y_test, y_pred_qda, average='weighted'),\n",
        "        f1_score(y_test, y_pred_svm, average='weighted'),\n",
        "        f1_score(y_test, y_pred_rf, average='weighted')\n",
        "    ],\n",
        "    'Precision': [\n",
        "        precision_score(y_test, y_pred_lr, average='weighted'),\n",
        "        precision_score(y_test, y_pred_qda, average='weighted', zero_division=0),\n",
        "        precision_score(y_test, y_pred_svm, average='weighted'),\n",
        "        precision_score(y_test, y_pred_rf, average='weighted')\n",
        "    ],\n",
        "    'Recall': [\n",
        "        recall_score(y_test, y_pred_lr, average='weighted'),\n",
        "        recall_score(y_test, y_pred_qda, average='weighted'),\n",
        "        recall_score(y_test, y_pred_svm, average='weighted'),\n",
        "        recall_score(y_test, y_pred_rf, average='weighted')\n",
        "    ]\n",
        "}\n",
        "\n",
        "df_metrics = pd.DataFrame(metrics)\n",
        "print(df_metrics.round(4))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}